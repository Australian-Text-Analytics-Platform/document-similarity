{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd1b4a84",
   "metadata": {},
   "source": [
    "# Document Similarity (English)\n",
    "In this notebook, you will use the DocumentSimilarity tool to identify similar documents in the English language and decide whether to keep or remove them from the corpus.  \n",
    "\n",
    "**Note:** this tool uses [MinHash](https://ekzhu.com/datasketch/minhash.html) to estimate the Jaccard similarity between sets of documents. MinHash is introduced by Andrei Z. Broder in this [paper](https://cs.brown.edu/courses/cs253/papers/nearduplicate.pdf).\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "For any questions, feedback, and/or comments about the tool, please contact the Sydney Informatics Hub at [sih.info@sydney.edu.au](mailto:sih.info@sydney.edu.au?subject=[ATAP]%20Document%20Similarity%20Tool%20inquiry).</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Jupyter Notebook User Guide</b> \n",
    "\n",
    "If you are new to Jupyter Notebook, feel free to take a quick look at [this user guide](documents/jupyter-notebook-guide.pdf) for basic information on how to use a notebook.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Document Similarity User Guide</b>\n",
    "\n",
    "For instructions on how to use the Document Similarity tool, please refer to the [Document Similarity User Guide](documents/docsim-help-pages.pdf).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1e7222",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "Before you begin, you need to import the DocumentSimilarity package and the necessary libraries and initiate them to run in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5f48b4-f568-43c4-b457-bbb584c463f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the DocumentSimilarity tool\n",
    "print('Loading DocumentSimilarity...')\n",
    "from atap_corpus_loader import CorpusLoader\n",
    "from document_similarity import DocumentSimilarity\n",
    "\n",
    "# initialize the DocumentSimilarity\n",
    "ds = DocumentSimilarity()\n",
    "print('Finished loading.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775c91f2",
   "metadata": {},
   "source": [
    "## 2. Load the data\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "This notebook will allow you to upload text data in one or more text files, each file contains one document. Alternatively, you can also upload multiple texts as an excel or CSV spreadsheet, in which each row is considered as one document ([see an example here](https://github.com/Sydney-Informatics-Hub/HASS-29_Quotation_Tool/blob/main/documents/sample_texts.xlsx)). Multiple files can be zipped and uploaded as a single archive file.\n",
    "</div>\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "Execute the next cell to run the [*ATAP corpus loader*](https://github.com/Australian-Text-Analytics-Platform/atap-corpus-loader) *UI* so that you can upload your files and build your corpus following the instructions below. Supported file types are .txt, .csv, .xlsx or a zip archive of these file types.  \n",
    "Once a corpus is successfully built, you can continue with the rest of the notebook to run the Document Similarity Tool with your corpus.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Using the ATAP corpus loader to load your dataset/corpus</b> <br>\n",
    "<td><img src='./img/corpus_loader.png' style='width: 1000px'/></td> <br>\n",
    "In order to use the document similarity tool, the user needs to build their corpus with the ATAP corpus loader. As a brief overview, the steps to use the loader are as follows (Please check the picture above for locations referred by superscript numbers):\n",
    "\n",
    "1. Upload your text files using the file explorer pane on the left<sup>1</sup>. <p>If the pane is not activated, clicking on the folder icon<sup>2</sup> will show you the file explorer pane.\n",
    "Files can be uploaded into any folder by either drag-n-drop or via the upload button<sup>3</sup> <br>\n",
    "Wait until your corpus is uploaded before you return to the notebook and execute the codes.\n",
    "\n",
    "2. Execute the following code cell to run the ATAP Corpus Loader in order to build your corpus from the uploaded files, all supported filetypes will be displayed and can be filtered<sup>4</sup> in the corpus-loader.\n",
    "\n",
    "3. Choose the files in the selector pane<sup>5</sup>, then click the 'Load as corpus' button<sup>6</sup>.  \n",
    "If loading from a spreadsheet with multiple columns, first, select the correct header of the column that contains the text data<sup>7</sup>. Then make sure the required metadata columns are checked<sup>8</sup> with the correct datatype<sup>9</sup> for your corpus.  \n",
    "For example, if one column consists of text, the datatype TEXT is appropriate and no changes are necessary.  \n",
    "If plain text files are loaded, the Corpus Loader also automatically creates and includes the filename as TEXT type metadata.\n",
    "\n",
    "4. Give your corpus a name<sup>10</sup> and click on the button “Build corpus”<sup>11</sup>. Wait until you receive the message “Corpus … built successfully”.   \n",
    "Review your corpus in the Corpus Overview or continue immediately to the next code cell in the notebook.  \n",
    "Refer to the screenshot above for each necessary operation.<br>\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "More information about the ATAP corpus loader is provided in the [User Guide](documents/Corpus%20Loader%20User%20Guide.pdf).\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e25599-5463-46c7-8c08-8054e41215eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_loader: CorpusLoader = CorpusLoader(\"./\", )\n",
    "corpus_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb4e1af-a6c4-4935-9a9a-cc6fbce1630f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "**Automatic deduplication of identical documents within the corpus**\n",
    "    \n",
    "The Document Similarity Tool is designed to find the documents in your corpus that are similar, but not 100% identical. As a first step, the tool will therefore aim to identify all identical documents in the corpus and undertake an automatic deduplication. For these identical documents, only the first document (according to alphabetical order by “text_name” or filename) will be retained in the corpus. The Jaccard-based similarity analysis below is then only run on the deduplicated version of the corpus to avoid including identical documents in the pairwise display. You can see the names of all identical documents in your corpus by executing the following cell, which allows you to export the relevant table as a CSV file. This table provides the filename of the retained file in the ‘kept’ column and the file names of the relevant identical (excluded) files in subsequent numbered columns. For example, the column ‘1’ contains the file name of the first duplicate of the file in the ‘kept’ column, and so on – this depends on the number of duplicates identified.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a02173b-e682-4be9-8d85-1bd560e7e59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the corpus that was last built for processing. \n",
    "# Alternatively, one can replace the first line of code with \"corpus = corpus_loader.get_corpus('corpusname')\"\n",
    "corpus = corpus_loader.get_latest_corpus()\n",
    "ds.set_text_df(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14aaf672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display uploaded text\n",
    "n=5\n",
    "\n",
    "ds.text_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69966b64",
   "metadata": {},
   "source": [
    "## 3. Calculate Document Similarity\n",
    "Once your texts have been uploaded, you can begin to calculate the similarity between documents in the corpus. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tools:</b>    \n",
    "\n",
    "- MinHash: fast implementation of estimating Jaccard similarity between documents in the corpus.  \n",
    "- Gensim: to tokenize the text.  \n",
    "    \n",
    "<b>Note:</b> in general, Gensim splits the text whenever whitespace or punctuation is encountered and digits are excluded, e.g., the text \"Here's to victory no 2\" will be tokenized into five tokens: \"Here\", \"s\", \"to\", \"victory\" and \"no\". For more information, please visit [this page](https://radimrehurek.com/gensim/utils.html#gensim.utils.tokenize).\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Memory limitation in Binder</b> \n",
    "    \n",
    "The free Binder deployment is only guaranteed a maximum of 2GB memory. Processing very large text files may cause the session (kernel) to re-start due to insufficient memory. Check [the user guide](https://github.com/Australian-Text-Analytics-Platform/semantic-tagger/blob/main/documents/jupyter-notebook-guide.pdf) for more info. \n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Parameters for calculating similarity</b> \n",
    "    \n",
    "The DocumentSimilarity tool uses Jaccard similarity to measure the similarity between documents. In the code below, we have specified and explained the default parameters for calculating the Jaccard similarity. However, you can also change these parameters should you wish. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a5539d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER SPECIFIES THESE VARIABLES\n",
    "# set the n-gram size (the number of words used to detect similarity), \n",
    "# e.g., n-gram=1 means compare every word ('apple' and 'orange'), \n",
    "# n-gram=2 means compare every pair of words ('one apple' and 'two oranges'), etc.\n",
    "ngram_value = 1\n",
    "\n",
    "# select whether to calculate actual or estimated Jaccard similarity \n",
    "# to measure the similarity between documents \n",
    "# we recommend using estimated Jaccard similarity for large corpus of documents (faster)\n",
    "actual_jaccard = False # True or False\n",
    "\n",
    "# whether to exclude punctuations when calculating Jaccard similarity\n",
    "ds.exclude_punc = True # True or False\n",
    "\n",
    "# set the number of permutation functions (num_perm) parameter for estimating Jaccard similarity\n",
    "# higher permutation functions improves the accuracy, but also increases query cost\n",
    "num_perm = 256\n",
    "\n",
    "# anything with >= the cutoff will be identified as similar documents\n",
    "similarity_cutoff = 0.6 # value should be between 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12845d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# begin the process of calculating similarity and identify similar documents\n",
    "ds.calculate_similarity(ngram_value, num_perm, similarity_cutoff, actual_jaccard)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76123092",
   "metadata": {},
   "source": [
    "## 3. Analyse similar documents\n",
    "Once the tool has finished calculating the document similarity, you can begin to analyse the outcome.  \n",
    "\n",
    "The graph below is a histogram of the count of similar documents in the corpus as measured by their Jaccard similarity. In this histogram, you can identify how many documents are found at different level of similarity measures.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Histogram of similar documents</b> \n",
    "    \n",
    "The x-axis on the histogram shows the Jaccard similarity scores for every document in the corpus, and the y-axis (the height of the bar) tells us how many similar documents are found at those Jaccard similarity score ranges. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f144e38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the similarity count accross the entire corpus\n",
    "ds.plot_hash_similarity_by_source(ds.deduplication_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1074b7b4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Heatmap of similar documents</b> \n",
    "    \n",
    "The below heatmap shows the Jaccard similarity scores between pair of similar documents, with the x- and y-axes showing the text_id of the similar document pairs (you can hover over the similar nodes to display the text name pairs). Please note that the heatmap only displays pair of similar documents with scores above the similarity cut-off, as defined earlier.  \n",
    "</div>  \n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Large number of similar documents</b> \n",
    "    \n",
    "You can resize the heatmap, adjust the font size or the font color to better visualize your data by specifying the below parameters. You can also zoom in/out of the heatmap, move it around, save and download it to your local computer using the interactive tool on the right hand-side of the heatmap.  \n",
    "\n",
    "<b>Note:</b> visualizing a large number of similar document pairs (**>500**) may slow down the notebook.   \n",
    "</div>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Input before plotting</b> \n",
    "    \n",
    "To avoid plotting oversized figure, the user is asked to **specify the range** of matched documents to be included in the heatmap.\n",
    "Entering **'n'** will cancel the figure generation.\n",
    "Entering **'y'** will proceed with **all pairs** of similar documents.\n",
    "Entering an **integer number**, such 30, will generate the figure with the top-30 pairs of the similar documents.\n",
    "Entering a number range like **15-45** will generate the figure with the selected range (15 to 45) of the document pairs.\n",
    "    \n",
    "**Press Enter Key after inputting.**\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b074f14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the plot width, height, font size and color\n",
    "plot_width = 900 # increase plot width if necessary\n",
    "plot_height = 800 # increase plot height if necessary\n",
    "font_size = '14px'\n",
    "text_color = 'white' # 'black' or 'white' would usually work for most scenarios\n",
    "\n",
    "print('\\033[1mVisualizing a large number of similar document pairs (>500) may slow down the notebook.\\033[0m')\n",
    "print('There are \\033[1m{}\\033[0m document pairs in the current process'.format(ds.deduplication_df.shape[0]))\n",
    "plot_range = input(\"\"\"Enter the range of documents pairs to be plotted, e.g. y, n, 10-25, or 30.\"\"\")\n",
    "\n",
    "# plot heatmap of Jaccard similarity\n",
    "ds.plot_heatmap_similarity(similarity_cutoff,\n",
    "                                plot_width,\n",
    "                                plot_height,\n",
    "                                font_size,\n",
    "                                text_color,\n",
    "                                plot_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4738a90d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Analyse similar documents</b> \n",
    "\n",
    "Below you can generate a list of similar documents (in pairs) found by the tool, based on the similarity cutoff specified earlier. By default, the tool makes recommendations on whether to 'keep' or 'remove' each similar document (the tool will recommend to remove the document with the lower word count, if the Jaccard similarity is above the specified threshold). However, using the below tool, you can generate each pair of similar documents (by specifying the row index you wish to analyse), analyse them, and update the action/recommendation as you see fit.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Similar documents table</b> \n",
    "\n",
    "The table below displays only those texts identified as similar based on the Jaccard similarity cut-off selected earlier and the number of texts included in the table display therefore also informs you how many texts in your corpus are identified as within the cut-off threshold.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a950215",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.display_deduplication_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5a76fa",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>What information is included in the above table?</b> \n",
    "\n",
    "**text_id1/2:** the text id of the pair of similar documents.\n",
    "    \n",
    "**text_name1/2:** the text name of the pair of similar documents.\n",
    "   \n",
    "**word_count1/2:** the word count of the pair of similar documents.\n",
    "\n",
    "**status1/2:** whether to 'keep' or 'remove' each similar document.\n",
    "\n",
    "**similarity:** the Jaccard similarity between the pair of similar documents.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "    \n",
    "**Caveat: Discrepancies in the highlighted side-by-side comparison**\n",
    "\n",
    "In the display of document pairs where differences between texts are highlighted for checking by users, only document pairs based on the Jaccard similarity parameters are included. However, this visualisation uses the python function difflib which is independent from the Jaccard calculation and may thus highlight differences in punctuation (regardless of previous settings) and this function may also at times contain incorrectly highlighted text blocks. Despite this caveat, the visualisation should still be helpful in allowing you to decide which of the two texts you want to ‘keep’ or ‘remove’.\n",
    " \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effbb68b",
   "metadata": {},
   "source": [
    "## 5. Save duplicated/non-duplicated texts\n",
    "Once you are happy with the list of texts that you want to keep, you can run the below code to save the non-duplicated texts (those with 'keep' status) or the duplicated ones (those with 'remove' status) into a zip of text (.txt) files and download them to your local computer.\n",
    "\n",
    "Remember that identical texts were already removed in the first step above and that this process of checking for similar texts was only run on the remaining (non-identical) texts. You can see the number of saved files in the progress bar which appears after you click ‘Save non-duplicated texts’ or after you click ‘Save duplicated texts’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018ecab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_to_display=5\n",
    "\n",
    "ds.finalise_and_save(rows_to_display)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd1b4a84",
   "metadata": {},
   "source": [
    "# Document Similarity (English)\n",
    "\n",
    "In this notebook, you will use the DocumentSimilarity tool to identify similar documents in the English language and decide whether to keep or remove them from the corpus.  \n",
    "\n",
    "**Note:** this tool uses [MinHash](https://ekzhu.com/datasketch/minhash.html) to estimate the Jaccard similarity between sets of documents. MinHash is introduced by Andrei Z. Broder in this [paper](https://cs.brown.edu/courses/cs253/papers/nearduplicate.pdf).\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>User guide to using a Jupyter Notebook</b> \n",
    "\n",
    "If you are new to Jupyter Notebook, feel free to take a quick look at [this user guide](https://github.com/Australian-Text-Analytics-Platform/semantic-tagger/blob/main/documents/jupyter-notebook-guide.pdf) for basic information on how to use a notebook.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1e7222",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Setup\n",
    "Before you begin, you need to import the DocumentSimilarity package and the necessary libraries and initiate them to run in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "990c5027-1647-4409-9b67-ef40fa03aeed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from notebook.notebookapp import NotebookApp\n",
    "\n",
    "app = NotebookApp()\n",
    "app.load_config_file()\n",
    "\n",
    "assert app.tornado_settings is not None, \"Jupyter configuration file is not loaded\"\n",
    "assert app.tornado_settings.get('websocket_max_message_size') > 1*1024*1024*1024, \"Jupyter configuration file is not loaded\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e7bef56-df84-47d0-8ec3-1725c6a15b47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasketch in /Users/hcha9747/workspace/quotation-tool/.venv-main/lib/python3.10/site-packages (1.6.0)\n",
      "Collecting seaborn\n",
      "  Using cached seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
      "Collecting gensim\n",
      "  Downloading gensim-4.3.2-cp310-cp310-macosx_11_0_arm64.whl (24.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.0/24.0 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: bokeh in /Users/hcha9747/workspace/quotation-tool/.venv-main/lib/python3.10/site-packages (3.1.1)\n",
      "Collecting swifter\n",
      "  Downloading swifter-1.4.0.tar.gz (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11 in /Users/hcha9747/workspace/quotation-tool/.venv-main/lib/python3.10/site-packages (from datasketch) (1.25.0)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /Users/hcha9747/workspace/quotation-tool/.venv-main/lib/python3.10/site-packages (from datasketch) (1.11.2)\n",
      "Requirement already satisfied: pandas>=0.25 in /Users/hcha9747/workspace/quotation-tool/.venv-main/lib/python3.10/site-packages (from seaborn) (2.0.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /Users/hcha9747/workspace/quotation-tool/.venv-main/lib/python3.10/site-packages (from seaborn) (3.7.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/hcha9747/workspace/quotation-tool/.venv-main/lib/python3.10/site-packages (from gensim) (6.3.0)\n",
      "Requirement already satisfied: Jinja2>=2.9 in /Users/hcha9747/workspace/quotation-tool/.venv-main/lib/python3.10/site-packages (from bokeh) (3.1.2)\n",
      "Requirement already satisfied: contourpy>=1 in /Users/hcha9747/workspace/quotation-tool/.venv-main/lib/python3.10/site-packages (from bokeh) (1.1.0)\n",
      "Requirement already satisfied: packaging>=16.8 in /Users/hcha9747/workspace/quotation-tool/.venv-main/lib/python3.10/site-packages (from bokeh) (23.1)\n",
      "Requirement already satisfied: pillow>=7.1.0 in /Users/hcha9747/workspace/quotation-tool/.venv-main/lib/python3.10/site-packages (from bokeh) (10.0.0)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /Users/hcha9747/workspace/quotation-tool/.venv-main/lib/python3.10/site-packages (from bokeh) (6.0)\n",
      "Requirement already satisfied: tornado>=5.1 in /Users/hcha9747/workspace/quotation-tool/.venv-main/lib/python3.10/site-packages (from bokeh) (6.3.2)\n",
      "Requirement already satisfied: xyzservices>=2021.09.1 in /Users/hcha9747/workspace/quotation-tool/.venv-main/lib/python3.10/site-packages (from bokeh) (2023.5.0)\n",
      "Requirement already satisfied: psutil>=5.6.6 in /Users/hcha9747/workspace/quotation-tool/.venv-main/lib/python3.10/site-packages (from swifter) (5.9.5)\n",
      "Collecting dask[dataframe]>=2.10.0 (from swifter)\n",
      "  Downloading dask-2023.9.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.33.0 in /Users/hcha9747/workspace/quotation-tool/.venv-main/lib/python3.10/site-packages (from swifter) (4.65.0)\n",
      "Requirement already satisfied: click>=8.0 in /Users/hcha9747/workspace/quotation-tool/.venv-main/lib/python3.10/site-packages (from dask[dataframe]>=2.10.0->swifter) (8.1.3)\n",
      "Collecting cloudpickle>=1.5.0 (from dask[dataframe]>=2.10.0->swifter)\n",
      "  Using cached cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Collecting fsspec>=2021.09.0 (from dask[dataframe]>=2.10.0->swifter)\n",
      "  Downloading fsspec-2023.9.0-py3-none-any.whl (173 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting partd>=1.2.0 (from dask[dataframe]>=2.10.0->swifter)\n",
      "  Using cached partd-1.4.0-py3-none-any.whl (18 kB)\n",
      "Collecting toolz>=0.10.0 (from dask[dataframe]>=2.10.0->swifter)\n",
      "  Using cached toolz-0.12.0-py3-none-any.whl (55 kB)\n",
      "Collecting importlib-metadata>=4.13.0 (from dask[dataframe]>=2.10.0->swifter)\n",
      "  Using cached importlib_metadata-6.8.0-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/hcha9747/workspace/quotation-tool/.venv-main/lib/python3.10/site-packages (from Jinja2>=2.9->bokeh) (2.1.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/hcha9747/workspace/quotation-tool/.venv-main/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/hcha9747/workspace/quotation-tool/.venv-main/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.40.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/hcha9747/workspace/quotation-tool/.venv-main/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/hcha9747/workspace/quotation-tool/.venv-main/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/hcha9747/workspace/quotation-tool/.venv-main/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/hcha9747/workspace/quotation-tool/.venv-main/lib/python3.10/site-packages (from pandas>=0.25->seaborn) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/hcha9747/workspace/quotation-tool/.venv-main/lib/python3.10/site-packages (from pandas>=0.25->seaborn) (2023.3)\n",
      "Collecting zipp>=0.5 (from importlib-metadata>=4.13.0->dask[dataframe]>=2.10.0->swifter)\n",
      "  Using cached zipp-3.16.2-py3-none-any.whl (7.2 kB)\n",
      "Collecting locket (from partd>=1.2.0->dask[dataframe]>=2.10.0->swifter)\n",
      "  Using cached locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/hcha9747/workspace/quotation-tool/.venv-main/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
      "Building wheels for collected packages: swifter\n",
      "  Building wheel for swifter (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for swifter: filename=swifter-1.4.0-py3-none-any.whl size=16507 sha256=b9b7b511aa6c3df400530456261162be513f317eda7f6b24a56dde9aaee89dd7\n",
      "  Stored in directory: /Users/hcha9747/Library/Caches/pip/wheels/e4/cf/51/0904952972ee2c7aa3709437065278dc534ec1b8d2ad41b443\n",
      "Successfully built swifter\n",
      "Installing collected packages: zipp, toolz, locket, fsspec, cloudpickle, partd, importlib-metadata, gensim, seaborn, dask, swifter\n",
      "Successfully installed cloudpickle-2.2.1 dask-2023.9.0 fsspec-2023.9.0 gensim-4.3.2 importlib-metadata-6.8.0 locket-1.0.0 partd-1.4.0 seaborn-0.12.2 swifter-1.4.0 toolz-0.12.0 zipp-3.16.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install datasketch seaborn gensim bokeh swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2eaeb9c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DocumentSimilarity...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"e4bfca53-4810-42f5-aa50-cf0b76317d31\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "const JS_MIME_TYPE = 'application/javascript';\n",
       "  const HTML_MIME_TYPE = 'text/html';\n",
       "  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  const CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    const script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    const cell = handle.cell;\n",
       "\n",
       "    const id = cell.output_area._bokeh_element_id;\n",
       "    const server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd_clean, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            const id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd_destroy);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    const output_area = handle.output_area;\n",
       "    const output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      const bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      const script_attrs = bk_div.children[0].attributes;\n",
       "      for (let i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      const toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    const events = require('base/js/events');\n",
       "    const OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  const NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    const el = document.getElementById(\"e4bfca53-4810-42f5-aa50-cf0b76317d31\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.1.1.min.js\"];\n",
       "  const css_urls = [];\n",
       "\n",
       "  const inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "          for (let i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      const cell = $(document.getElementById(\"e4bfca53-4810-42f5-aa50-cf0b76317d31\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"e4bfca53-4810-42f5-aa50-cf0b76317d31\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.1.1.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n          for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\nif (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"e4bfca53-4810-42f5-aa50-cf0b76317d31\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading.\n"
     ]
    }
   ],
   "source": [
    "# import the DocumentSimilarity tool\n",
    "print('Loading DocumentSimilarity...')\n",
    "from document_similarity import DocumentSimilarity, DownloadFileLink\n",
    "import sys\n",
    "\n",
    "# initialize the DocumentSimilarity\n",
    "ds = DocumentSimilarity()\n",
    "print('Finished loading.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775c91f2",
   "metadata": {},
   "source": [
    "## 2. Load the data\n",
    "This notebook will allow you to upload text data in a text file (or a number of text files). Alternatively, you can also upload text inside a text column inside your excel spreadsheet ([see an example here](https://github.com/Sydney-Informatics-Hub/HASS-29_Quotation_Tool/blob/main/documents/sample_texts.xlsx)).  \n",
    "\n",
    "<table style='margin-left: 10px'><tr>\n",
    "<td> <img src='./img/txt_icon.png' style='width: 45px'/> </td>\n",
    "<td> <img src='./img/xlsx_icon.png' style='width: 55px'/> </td>\n",
    "<td> <img src='./img/csv_icon.png' style='width: 45px'/> </td>\n",
    "<td> <img src='./img/zip_icon.png' style='width: 45px'/> </td>\n",
    "</tr></table>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Uploading your text files</b> \n",
    "    \n",
    "If you have a large number of text files (more than 10MB in total), we suggest you compress (zip) them and upload the zip file instead. If you need assistance on how to compress your file, please check [the user guide](https://github.com/Australian-Text-Analytics-Platform/semantic-tagger/blob/main/documents/jupyter-notebook-guide.pdf) for more info. \n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Large file upload</b> \n",
    "    \n",
    "If you have ongoing issues with the file upload, please re-launch the notebook via Binder again. If the issue persists, consider restarting your computer.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e0a3574",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2df397a0aaea4044be83c21ebe99a9dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FileUpload(value=(), accept='.txt, .xlsx, .csv, .zip', description='Upload your files (txt, csv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading large files may take a while. Please be patient.\n",
      "\u001b[1mPlease wait and do not press any buttons until the progress bar appears...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# upload the text files and/or excel spreadsheets onto the system\n",
    "display(ds.upload_box)\n",
    "print('Uploading large files may take a while. Please be patient.')\n",
    "print('\\033[1mPlease wait and do not press any buttons until the progress bar appears...\\033[0m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14aaf672",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DocumentSimilarity' object has no attribute 'text_df'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# display uploaded text\u001b[39;00m\n\u001b[1;32m      2\u001b[0m n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext_df\u001b[49m\u001b[38;5;241m.\u001b[39mhead(n)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DocumentSimilarity' object has no attribute 'text_df'"
     ]
    }
   ],
   "source": [
    "# display uploaded text\n",
    "n=5\n",
    "\n",
    "ds.text_df.head(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69966b64",
   "metadata": {},
   "source": [
    "## 3. Calculate Document Similarity\n",
    "Once your texts have been uploaded, you can begin to calculate the similarity between documents in the corpus. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tools:</b>    \n",
    "\n",
    "- MinHash: fast implementation of estimating Jaccard similarity between documents in the corpus.  \n",
    "- Gensim: to tokenize the text.  \n",
    "    \n",
    "<b>Note:</b> in general, Gensim splits the text whenever whitespace or punctuation is encountered and digits are excluded, e.g., the text \"Here's to victory no 2\" will be tokenized into five tokens: \"Here\", \"s\", \"to\", \"victory\" and \"no\". For more information, please visit [this page](https://radimrehurek.com/gensim/utils.html#gensim.utils.tokenize).\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Memory limitation in Binder</b> \n",
    "    \n",
    "The free Binder deployment is only guaranteed a maximum of 2GB memory. Processing very large text files may cause the session (kernel) to re-start due to insufficient memory. Check [the user guide](https://github.com/Australian-Text-Analytics-Platform/semantic-tagger/blob/main/documents/jupyter-notebook-guide.pdf) for more info. \n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Parameters for calculating similarity</b> \n",
    "    \n",
    "The DocumentSimilarity tool uses Jaccard similarity to measure the similarity between documents. In the code below, we have specified and explained the default parameters for calculating the Jaccard similarity. However, you can also change these parameters should you wish. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a5539d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER SPECIFIES THESE VARIABLES\n",
    "# set the n-gram size (the number of words used to detect similarity), \n",
    "# e.g., n-gram=1 means compare every word ('apple' and 'orange'), \n",
    "# n-gram=2 means compare every pair of words ('one apple' and 'two oranges'), etc.\n",
    "ngram_value = 1\n",
    "\n",
    "# select whether to calculate actual or estimated Jaccard similarity \n",
    "# to measure the similarity between documents \n",
    "# we recommend using estimated Jaccard similarity for large corpus of documents (faster)\n",
    "actual_jaccard = False # True or False\n",
    "\n",
    "# whether to exclude punctuations when calculating Jaccard similarity\n",
    "ds.exclude_punc = False # True or False\n",
    "\n",
    "# set the number of permutation functions (num_perm) parameter for estimating Jaccard similarity\n",
    "# higher permutation functions improves the accuracy, but also increases query cost\n",
    "num_perm = 256\n",
    "\n",
    "# anything with >= the cutoff will be identified as similar documents\n",
    "similarity_cutoff = 0.5 # value should be between 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12845d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# begin the process of calculating similarity and identify similar documents\n",
    "ds.calculate_similarity(ngram_value, num_perm, similarity_cutoff, actual_jaccard)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76123092",
   "metadata": {},
   "source": [
    "## 3. Analyse similar documents\n",
    "Once the tool has finished calculating the document similarity, you can begin to analyse the outcome.  \n",
    "\n",
    "The graph below is a histogram of the count of similar documents in the corpus as measured by their Jaccard similarity. In this histogram, you can identify how many documents are found at different level of similarity measures.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Histogram of similar documents</b> \n",
    "    \n",
    "The x-axis on the histogram shows the Jaccard similarity scores for every document in the corpus, and the y-axis (the height of the bar) tells us how many similar documents are found at those Jaccard similarity score ranges. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f144e38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the similarity count accross the entire corpus\n",
    "ds.plot_hash_similarity_by_source(ds.deduplication_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1074b7b4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Heatmap of similar documents</b> \n",
    "    \n",
    "The below heatmap shows the Jaccard similarity scores between pair of similar documents, with the x- and y-axes showing the text_id of the similar document pairs (you can hover over the similar nodes to display the text name pairs). Please note that the heatmap only displays pair of similar documents with scores above the similarity cut-off, as defined earlier.  \n",
    "</div>  \n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Large number of similar documents</b> \n",
    "    \n",
    "You can resize the heatmap, adjust the font size or the font color to better visualize your data by specifying the below parameters. You can also zoom in/out of the heatmap, move it around, save and download it to your local computer using the interactive tool on the right hand-side of the heatmap.  \n",
    "\n",
    "<b>Note:</b> visualizing a large number of similar document pairs (**>500**) may slow down the notebook.   \n",
    "</div>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Input before plotting</b> \n",
    "    \n",
    "To avoid plotting oversized figure, the user is asked to **specify the range** of matched documents to be included in the heatmap.\n",
    "Entering **'n'** will cancel the figure generation.\n",
    "Entering **'y'** will proceed with **all pairs** of similar documents.\n",
    "Entering an **integer number**, such 30, will generate the figure with the top-30 pairs of the similar documents.\n",
    "Entering a number range like **15-45** will generate the figure with the selected range (15 to 45) of the document pairs.\n",
    "    \n",
    "**Press Enter Key after inputting.**\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b074f14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the plot width, height, font size and color\n",
    "plot_width = 900 # increase plot width if necessary\n",
    "plot_height = 800 # increase plot height if necessary\n",
    "font_size = '14px'\n",
    "text_color = 'white' # 'black' or 'white' would usually work for most scenarios\n",
    "\n",
    "print('\\033[1mVisualizing a large number of similar document pairs (>500) may slow down the notebook.\\033[0m')\n",
    "print('There are \\033[1m{}\\033[0m document pairs in the current process'.format(ds.deduplication_df.shape[0]))\n",
    "plot_range = input(\"\"\"Enter the range of documents pairs to be plotted, e.g. y, n, 10-25, or 30.\"\"\")\n",
    "\n",
    "# plot heatmap of Jaccard similarity\n",
    "ds.plot_heatmap_similarity(similarity_cutoff,\n",
    "                                plot_width,\n",
    "                                plot_height,\n",
    "                                font_size,\n",
    "                                text_color,\n",
    "                                plot_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4738a90d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Analyse similar documents</b> \n",
    "\n",
    "Below you can generate a list of similar documents (in pairs) found by the tool, based on the similarity cutoff specified earlier. By default, the tool makes recommendations on whether to 'keep' or 'remove' each similar document (the tool will recommend to remove the document with the lower word count, if the Jaccard similarity is above the specified threshold). However, using the below tool, you can generate each pair of similar documents (by specifying the row index you wish to analyse), analyse them, and update the action/recommendation as you see fit.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Similar documents table</b> \n",
    "\n",
    "The table below displays only those texts identified as similar based on the Jaccard similarity cut-off selected earlier and the number of texts included in the table display therefore also informs you how many texts in your corpus are identified as within the cut-off threshold.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a950215",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.display_deduplication_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5a76fa",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>What information is included in the above table?</b> \n",
    "\n",
    "**text_id1/2:** the text id of the pair of similar documents.\n",
    "    \n",
    "**text_name1/2:** the text name of the pair of similar documents.\n",
    "   \n",
    "**word_count1/2:** the word count of the pair of similar documents.\n",
    "\n",
    "**status1/2:** whether to 'keep' or 'remove' each similar document.\n",
    "\n",
    "**similarity:** the Jaccard similarity between the pair of similar documents.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effbb68b",
   "metadata": {},
   "source": [
    "## 5. Save duplicated/non-duplicated texts\n",
    "Once you are happy with the list of texts that you want to keep, you can run the below code to save the non-duplicated texts (those with 'keep' status) or the duplicated ones (those with 'remove' status) into a zip of text (.txt) files and download them to your local computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018ecab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_to_display=5\n",
    "\n",
    "ds.finalise_and_save(rows_to_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a96349-1702-4abb-a765-da2735b47724",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

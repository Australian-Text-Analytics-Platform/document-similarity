{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd1b4a84",
   "metadata": {},
   "source": [
    "# Document Similarity (English)\n",
    "\n",
    "In this notebook, you will use the DocumentSimilarity tool to identify similar documents in the English language and decide whether to keep or remove them from the corpus.  \n",
    "\n",
    "**Note:** this tool uses [MinHash](https://ekzhu.com/datasketch/minhash.html) to estimate the Jaccard similarity between sets of documents. MinHash is introduced by Andrei Z. Broder in this [paper](https://cs.brown.edu/courses/cs253/papers/nearduplicate.pdf).\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>User guide to using a Jupyter Notebook</b> \n",
    "\n",
    "If you are new to Jupyter Notebook, feel free to take a quick look at [this user guide](https://github.com/Australian-Text-Analytics-Platform/semantic-tagger/blob/main/documents/jupyter-notebook-guide.pdf) for basic information on how to use a notebook.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1e7222",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "Before you begin, you need to import the DocumentSimilarity package and the necessary libraries and initiate them to run in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaeb9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the DocumentSimilarity tool\n",
    "print('Loading DocumentSimilarity...')\n",
    "from document_similarity import DocumentSimilarity, DownloadFileLink\n",
    "\n",
    "# initialize the DocumentSimilarity\n",
    "ds = DocumentSimilarity()\n",
    "print('Finished loading.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775c91f2",
   "metadata": {},
   "source": [
    "## 2. Load the data\n",
    "This notebook will allow you upload text data in a text file (or a number of text files). Alternatively, you can also upload text inside a text column inside your excel spreadsheet ([see an example here](https://github.com/Sydney-Informatics-Hub/HASS-29_Quotation_Tool/blob/main/documents/sample_texts.xlsx)).  \n",
    "\n",
    "<table style='margin-left: 10px'><tr>\n",
    "<td> <img src='./img/txt_icon.png' style='width: 45px'/> </td>\n",
    "<td> <img src='./img/xlsx_icon.png' style='width: 55px'/> </td>\n",
    "<td> <img src='./img/csv_icon.png' style='width: 45px'/> </td>\n",
    "<td> <img src='./img/zip_icon.png' style='width: 45px'/> </td>\n",
    "</tr></table>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Uploading your text files</b> \n",
    "    \n",
    "If you have a large number of text files (more than 10MB in total), we suggest you compress (zip) them and upload the zip file instead. If you need assistance on how to compress your file, please check [the user guide](https://github.com/Australian-Text-Analytics-Platform/semantic-tagger/blob/main/documents/jupyter-notebook-guide.pdf) for more info. \n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Large file upload</b> \n",
    "    \n",
    "If you have ongoing issues with the file upload, please re-launch the notebook via Binder again. If the issue persists, consider restarting your computer.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0a3574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload the text files and/or excel spreadsheets onto the system\n",
    "display(ds.upload_box)\n",
    "print('Uploading large files may take a while. Please be patient.')\n",
    "print('\\033[1mPlease wait and do not press any buttons until the progress bar appears...\\033[0m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14aaf672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display uploaded text\n",
    "n=5\n",
    "\n",
    "ds.text_df.head(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69966b64",
   "metadata": {},
   "source": [
    "## 3. Calculate Document Similarity\n",
    "Once your texts have been uploaded, you can begin to calculate the similarity between documents in the corpus. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tools:</b>    \n",
    "\n",
    "- MinHash: fast implementation of estimating Jaccard similarity between documents in the corpus.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Memory limitation in Binder</b> \n",
    "    \n",
    "The free Binder deployment is only guaranteed a maximum of 2GB memory. Processing very large text files may cause the session (kernel) to re-start due to insufficient memory. Check [the user guide](https://github.com/Australian-Text-Analytics-Platform/semantic-tagger/blob/main/documents/jupyter-notebook-guide.pdf) for more info. \n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Parameters for calculating similarity</b> \n",
    "    \n",
    "The DocumentSimilarity tool uses Jaccard similarity to measure the similarity between documents. In the code below, we have specified and explained the default parameters for calculating the Jaccard similarity. However, you can also change these parameters should you wish. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a5539d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER SPECIFIES THESE VARIABLES\n",
    "# set the n-gram size (the number of words used to detect similarity), \n",
    "# e.g., n-gram=1 means compare every word ('apple' and 'orange'), \n",
    "# n-gram=2 means compare every pair of words ('one apple' and 'two oranges'), etc.\n",
    "ngram_value = 1\n",
    "\n",
    "# select whether to calculate actual or estimated Jaccard similarity \n",
    "# to measure the similarity between documents \n",
    "# we recommend using estimated Jaccard similarity for large corpus of documents (faster)\n",
    "actual_jaccard = False # True or False\n",
    "\n",
    "# set the number of permutation functions (num_perm) parameter for estimating Jaccard similarity\n",
    "# higher permutation functions improves the accuracy, but also increases query cost\n",
    "num_perm = 256\n",
    "\n",
    "# anything with >= the cutoff will be identified as similar documents\n",
    "similarity_cutoff = 0.5 # value should be between 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12845d7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# begin the process of calculating similarity and identify similar documents\n",
    "ds.calculate_similarity(ngram_value, num_perm, similarity_cutoff, actual_jaccard)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76123092",
   "metadata": {},
   "source": [
    "## 3. Analyse similar documents\n",
    "Once the tool has finished calculating the document similarity, you can begin to analyse the outcome.  \n",
    "\n",
    "The graph below is a histogram of the count of similar documents in the corpus as measured by their Jaccard similarity. In this histogram, you can identify how many documents are found at different level of similarity measures.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Histogram of similar documents</b> \n",
    "    \n",
    "The x-axis on the histogram shows the Jaccard similarity scores for every document in the corpus, and the y-axis (the height of the bar) tells us how many similar documents are found at those Jaccard similarity score ranges. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f144e38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the similarity count accross the entire corpus\n",
    "ds.plot_hash_similarity_by_source(ds.deduplication_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1074b7b4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Heatmap of similar documents</b> \n",
    "    \n",
    "The below heatmap shows the Jaccard similarity scores between pair of similar documents, with the x- and y-axes showing the text_id of the similar document pairs. Please note that the heatmap only displays pair of similar documents with scores above the similarity cut-off, as defined earlier.  \n",
    "</div>  \n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Large number of similar documents</b> \n",
    "    \n",
    "You can resize the heatmap, adjust the font size or the font color to better visualize your data by specifying the below parameters. You can also zoom in/out of the heatmap, move it around, save and download it to your local computer using the interactive tool on the right hand-side of the heatmap.  \n",
    "\n",
    "<b>Note:</b> visualizing a large number of similar document pairs (>1,000) may slow down the notebook.   \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b074f14f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# define the plot width, height, font size and color\n",
    "plot_width = 900 # increase plot width if necessary\n",
    "plot_height = 800 # increase plot height if necessary\n",
    "font_size = '14px'\n",
    "text_color = 'white' # 'black' or 'white' would usually work for most scenarios\n",
    "\n",
    "# plot heatmap of Jaccard similarity\n",
    "ds.plot_heatmap_similarity(similarity_cutoff,\n",
    "                                plot_width,\n",
    "                                plot_height,\n",
    "                                font_size,\n",
    "                                text_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4738a90d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Analyse similar documents</b> \n",
    "\n",
    "Below you can generate a list of similar documents (in pairs) found by the tool, based on the similarity cutoff specified earlier. By default, the tool makes recommendations on whether to 'keep' or 'remove' each similar document (the tool will recommend to remove the document with the lower word count, if the Jaccard similarity is above the specified threshold). However, using the below tool, you can generate each pair of similar documents (by specifying the row index you wish to analyse), analyse them, and update the action/recommendation as you see fit.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Similar documents table</b> \n",
    "\n",
    "The table below displays only those texts identified as similar based on the Jaccard similarity cut-off selected earlier and the number of texts included in the table display therefore also informs you how many texts in your corpus are identified as within the cut-off threshold.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a950215",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ds.display_deduplication_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5a76fa",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>What information is included in the above table?</b> \n",
    "\n",
    "**text_id1/2:** the text id of the pair of similar documents.\n",
    "    \n",
    "**text_name1/2:** the text name of the pair of similar documents.\n",
    "   \n",
    "**word_count1/2:** the word count of the pair of similar documents.\n",
    "\n",
    "**status1/2:** whether to 'keep' or 'remove' each similar document.\n",
    "\n",
    "**similarity:** the Jaccard similarity between the pair of similar documents.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effbb68b",
   "metadata": {},
   "source": [
    "## 5. Save non-duplicated texts\n",
    "Once you are happy with the list of texts that you want to keep, you can run the below code to save the non-duplicated text (those with 'keep' status) into a zip of text (.txt) files and download them to your local computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018ecab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=5\n",
    "\n",
    "ds.finalise_and_save(n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
